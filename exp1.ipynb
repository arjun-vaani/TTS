{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40eccaee-af5d-4458-940a-bcadbd5ae6bc",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c1a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import normal_inverse_gamma\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c256db49-ddab-40da-bded-fcc3e79be469",
   "metadata": {},
   "source": [
    "$$\n",
    "\\alpha, \\beta, \\lambda , \\mu  \\\\\n",
    "$$\n",
    "$$\n",
    "\\alpha > 0  \\\\\n",
    "$$\n",
    "$$\n",
    "\\lambda > 0  \\\\\n",
    "$$\n",
    "$$\n",
    "\\mu \\in \\mathbb{R}  \\\\\n",
    "$$\n",
    "$$\n",
    "abs(\\beta) < \\alpha \\\\\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1e9c5b-c9e6-4323-a6e4-1d85c0d3c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "N=4\n",
    "n_samples=2\n",
    "dataset_size= 10000\n",
    "def gen_zarr(N, n_samples, dataset_size):\n",
    "    dataset_zarr = zarr.create_array(\n",
    "       store=\"data/x_train.zarr\",\n",
    "       shape=(dataset_size, n_samples+ 1, N),\n",
    "       chunks=(10, n_samples+ 1, N),\n",
    "       dtype=\"float32\",\n",
    "        overwrite=True\n",
    "    )\n",
    "    return dataset_zarr\n",
    "dataset_zarr = gen_zarr(N, n_samples, dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e024f71a-dd94-4496-ba79-9adceb241f79",
   "metadata": {},
   "source": [
    "### X_train Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f8e26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "def my_sample_from_gamma(x):\n",
    "    inv_gamma = normal_inverse_gamma(*x)\n",
    "    x_ = inv_gamma.rvs()[0]\n",
    "    return x_\n",
    "    \n",
    "sample_from_gamma = np.vectorize(my_sample_from_gamma, signature=\"(n)->()\")\n",
    "\n",
    "def gen_X_train(N, dataset_size, rng, rng2, rng3, rng4, dataset_zarr):\n",
    "    nu_seed = rng.random((N, 1))\n",
    "    alpha_seed = 13 * rng.beta(rng2.random(), rng2.random(), size=(N, 1))\n",
    "    mu_loc = [\n",
    "        np.random.choice(np.array([-1, -0.5,0.6,0.3, 1]))\n",
    "        * np.random.beta(np.random.random(), np.random.random())\n",
    "        for _ in range(N)\n",
    "    ]\n",
    "    mu_scale = [np.random.beta(np.random.random(), np.random.random()) for _ in range(N)]\n",
    "    \n",
    "    mu_seed = rng.normal(loc=mu_loc, scale=mu_scale, size=(N, N))\n",
    "    mu_seed = np.diagonal(mu_seed)[None].T\n",
    "    lambda_seed = rng2.random((N, 1))\n",
    "    beta_seed = rng3.random((N, 1))\n",
    "    \n",
    "    params = np.hstack([mu_seed, lambda_seed, alpha_seed, beta_seed])\n",
    "    for _ in trange(dataset_size):\n",
    "        params_ = params.copy()\n",
    "        x = sample_from_gamma(params_)\n",
    "        dataset_zarr[_, 0] = x\n",
    "    return dataset_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177f596f-ee3b-4a21-8343-d46e9b9e2f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:23<00:00, 424.35it/s]\n"
     ]
    }
   ],
   "source": [
    "rng = default_rng(34)\n",
    "rng2 = default_rng(np.random.randint(1, 3090))\n",
    "rng3 = default_rng(np.random.randint(1, 3090))\n",
    "rng4 = default_rng(np.random.randint(1, 3090))\n",
    "\n",
    "dataset_zarr = gen_X_train(N, dataset_size, rng, rng2, rng3, rng4, dataset_zarr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d0d3f",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa442d35-15f3-44e0-a6b2-9c58b8af19b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import invgamma\n",
    "\n",
    "\n",
    "def mixture_kernel_sampler(x):\n",
    "    \"\"\"\n",
    "    Maps input x to a bimodal distribution where the two modes\n",
    "    diverge and the noise oscillates.\n",
    "    \"\"\"\n",
    "    # --- 1. Define Dynamic Parameters based on x ---\n",
    "\n",
    "    # Mode 1: Curves upward\n",
    "    mu_1 = 2 * x**2 + 1\n",
    "    # Mode 2: Curves downward\n",
    "    mu_2 = -2 * x**2 - 1\n",
    "\n",
    "    # Variance: Oscillates sinusoidally (Heteroscedasticity)\n",
    "    # High noise when sin is 1, low noise when sin is -1\n",
    "    sigma = 0.3 * np.abs(np.sin(4 * x)) + 0.05\n",
    "\n",
    "    # Mixing Probability: Transitions from Mode 1 to Mode 2 as x increases\n",
    "    # sigmoid function centered at 0\n",
    "    prob_mode_1 = 1 / (1 + np.exp(-5 * x))\n",
    "\n",
    "    # --- 2. Sampling Logic ---\n",
    "\n",
    "    # Step A: Choose which mode (gaussian) to sample from\n",
    "    # random choice based on prob_mode_1\n",
    "    mode_choice = np.random.rand() < prob_mode_1\n",
    "\n",
    "    # Step B: Sample from the chosen Gaussian\n",
    "    if mode_choice:\n",
    "        y = np.random.normal(loc=mu_1, scale=sigma)\n",
    "    else:\n",
    "        y = np.random.normal(loc=mu_2, scale=sigma)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def hierarchical_nig_sampler(x):\n",
    "    \"\"\"\n",
    "    Implements the BELLE Hierarchical Sampling mechanism [cite: 165-167].\n",
    "    The 'probabilistic space' itself is uncertain.\n",
    "    \"\"\"\n",
    "    # --- 1. Map x to Hyper-parameters ---\n",
    "    # This emulates the neural network projection layer\n",
    "\n",
    "    # Gamma (The 'expected' mean): Linear trend\n",
    "    gamma = 3 * x\n",
    "\n",
    "    # Nu (Evidence count): Higher x -> Higher confidence in the mean\n",
    "    nu = np.abs(x) + 1.0\n",
    "\n",
    "    # Alpha (Shape of variance dist):\n",
    "    # Low alpha = Heavy tails (high uncertainty about variance)\n",
    "    alpha = 2.0 + np.exp(-0.5 * x**3)  # High uncertainty near 0\n",
    "\n",
    "    # Beta (Scale of variance dist): Constant scale\n",
    "    beta = 0.5\n",
    "\n",
    "    # --- 2. Hierarchical Sampling Steps [cite: 166-167] ---\n",
    "\n",
    "    # Step A: Sample the Variance (Sigma^2) from Inverse Gamma\n",
    "    # Note: scipy invgamma takes 'a' (alpha) and 'scale' (beta)\n",
    "    sigma_sq = invgamma.rvs(a=alpha, scale=beta)\n",
    "\n",
    "    # Step B: Sample the Mean (Mu) conditioned on Sigma^2\n",
    "    # Variance of the mean is sigma^2 / nu\n",
    "    mean_variance = sigma_sq / nu\n",
    "    sampled_mu = np.random.normal(loc=gamma, scale=np.sqrt(mean_variance)) * x\n",
    "\n",
    "    # Step C: Sample the final data point y\n",
    "    y = np.random.normal(loc=sampled_mu, scale=np.sqrt(sigma_sq))\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def jump_diffusion_sampler(x):\n",
    "    \"\"\"\n",
    "    Samples from a process with continuous noise and rare, discrete jumps.\n",
    "    Useful for modeling systems with 'shocks' or 'glitches'.\n",
    "    \"\"\"\n",
    "    # 1. Continuous Drift Component (The 'Normal' behavior)\n",
    "    drift = np.sin(3 * x)\n",
    "    diffusion_noise = np.random.normal(0, 0.2)\n",
    "\n",
    "    # 2. Jump Component (The 'Rare Event')\n",
    "    # Probability of a jump increases dramatically as x gets far from 0\n",
    "    jump_prob = 0.05 + 0.4 * (np.abs(x) > 1.5)\n",
    "\n",
    "    is_jump = np.random.rand() < jump_prob\n",
    "\n",
    "    if is_jump:\n",
    "        # Jumps are large, discrete shifts\n",
    "        jump_magnitude = np.random.choice([-2, 2])\n",
    "        # Add some jitter to the jump\n",
    "        jump_val = jump_magnitude + np.random.normal(0, 0.5)\n",
    "    else:\n",
    "        jump_val = 0\n",
    "\n",
    "    y = drift + diffusion_noise + jump_val\n",
    "    return y\n",
    "\n",
    "\n",
    "def fractal_weierstrass_sampler(x, K=10):\n",
    "    \"\"\"\n",
    "    Samples from a distribution defined by a randomized fractal function.\n",
    "    x controls the 'roughness' and amplitude of the summation.\n",
    "    \"\"\"\n",
    "    # 1. Dynamic Fractal Parameters\n",
    "    # b: Frequency multiplier (must be > 1).\n",
    "    # We vary b slightly with x to create 'spectral shifting'\n",
    "    b = 2.0 + 0.5 * np.sin(x)\n",
    "\n",
    "    # a: Amplitude decay (0 < a < 1).\n",
    "    # x controls how fast high frequencies decay.\n",
    "    # x near 0 -> a near 1 -> Very rough/noisy (High fractal dimension)\n",
    "    # x far from 0 -> a near 0 -> Very smooth (Low fractal dimension)\n",
    "    a = 0.5 / (1 + np.abs(x))\n",
    "\n",
    "    y_sum = 0\n",
    "\n",
    "    # 2. Summation (The Weierstrass Function approximation)\n",
    "    for k in range(K):\n",
    "        # Randomized phase shift per component creates the 'kernel' variance\n",
    "        phi = np.random.uniform(0, 2 * np.pi)\n",
    "\n",
    "        # Term: amplitude * cos(frequency * x + phase)\n",
    "        term = (a**k) * np.cos((b**k) * np.pi * x + phi)\n",
    "        y_sum += term\n",
    "\n",
    "    # Add base noise\n",
    "    return y_sum + np.random.normal(0, 0.05)\n",
    "\n",
    "\n",
    "def stochastic_volatility_jump_sampler(x):\n",
    "    \"\"\"\n",
    "    Simulates a process with latent volatility and rare jumps.\n",
    "    x influences the 'stability' of the market regime.\n",
    "    \"\"\"\n",
    "    # 1. Regime Determination based on x\n",
    "    # if x > 0: 'Bull Market' (Drift up, low noise)\n",
    "    # if x < 0: 'Bear Market' (Drift down, high noise)\n",
    "\n",
    "    # Base parameters\n",
    "    if x > 0:\n",
    "        mu = 0.5 * x\n",
    "        base_vol = 0.1\n",
    "        jump_prob = 0.4  # Rare jumps\n",
    "    else:\n",
    "        mu = 0.5 * x\n",
    "        base_vol = 0.4  # High volatility\n",
    "        jump_prob = 0.2  # Frequent jumps\n",
    "\n",
    "    # 2. Stochastic Volatility Component\n",
    "    # Volatility itself is random (log-normal)\n",
    "    # This creates \"fat tails\" (Kurtosis) in the distribution\n",
    "    realized_vol = base_vol * np.exp(np.random.normal(0, 0.2))\n",
    "\n",
    "    # 3. Jump Component (Poisson Process)\n",
    "    is_jump = np.random.rand() < jump_prob\n",
    "\n",
    "    if is_jump:\n",
    "        # Jumps are usually negative panic events in this model\n",
    "        jump_size = np.random.normal(-2.0, 0.5)\n",
    "    else:\n",
    "        jump_size = 0\n",
    "\n",
    "    # 4. Final Sample\n",
    "    # y = Trend + Stochastic_Vol_Noise + Jump\n",
    "    y = mu + np.random.normal(0, realized_vol) + jump_size\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebd121-573e-478f-839c-2fc2bdbe4ae4",
   "metadata": {},
   "source": [
    "### Target Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "189edd03-2e1d-4c1f-bb1b-5a3d4ff72b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:25<00:00, 394.58it/s]\n"
     ]
    }
   ],
   "source": [
    "kernel_funcs = [mixture_kernel_sampler, hierarchical_nig_sampler, jump_diffusion_sampler, stochastic_volatility_jump_sampler, fractal_weierstrass_sampler]\n",
    "replace_ = True if N > 5 else False\n",
    "kernel_pos = np.random.choice(kernel_funcs, size=(N,), replace=replace_)\n",
    "\n",
    "def gen_targets(x, n_samples):\n",
    "    y_targets = []\n",
    "    for _ in range(n_samples):\n",
    "        target = [kernel_pos[i](x[i]) for i in range(4)]\n",
    "        y_targets.append(target)\n",
    "    return y_targets\n",
    "\n",
    "# with tqdm(total=dataset_size) as pbar:\n",
    "for i in trange(dataset_size):\n",
    "    _x = dataset_zarr[i, 0]\n",
    "    targets = gen_targets(_x, n_samples)\n",
    "    for j in range(n_samples):\n",
    "        dataset_zarr[i, j+1]= targets[j]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645f064-4e8d-4fba-8df5-fcc9d3b9873e",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b917637b-1f8b-43e4-9317-31cbaac78614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class TripletSplitDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset that takes an (N, 3, 4) array.\n",
    "    \n",
    "    Mapping strategy:\n",
    "    - The sample at index `idx` has shape (3, 4).\n",
    "    - Row 0 is treated as the Input (x).\n",
    "    - Row 1 is treated as Target 1 (y1).\n",
    "    - Row 2 is treated as Target 2 (y2).\n",
    "    \n",
    "    All outputs retain the shape (1, 4).\n",
    "    \"\"\"\n",
    "    def __init__(self, data_source):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_source (numpy.ndarray or torch.Tensor): Data of shape (N, 3, 4).\n",
    "        \"\"\"\n",
    "        self.data= data_source\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # We select the sample: shape (3, 4)\n",
    "        sample = self.data[idx]\n",
    "        \n",
    "        # Note on Slicing:\n",
    "        # Using sample[0] would return shape (4,).\n",
    "        # Using sample[0:1] keeps the dimension, returning shape (1, 4).\n",
    "        \n",
    "        # Input: First row (1, 4)\n",
    "        x = sample[0:1, :]\n",
    "        \n",
    "        # Output 1: Second row (1, 4)\n",
    "        y1 = sample[1:2, :]\n",
    "        \n",
    "        # Output 2: Third row (1, 4)\n",
    "        y2 = sample[2:3, :]\n",
    "        \n",
    "        return x, y1, y2\n",
    "\n",
    "dataset = TripletSplitDataset(data_source=dataset_zarr)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2188008e-227f-4d30-83c1-d3928f2f2d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 1.0975, -1.6968, -0.4248, -0.9426]],\n",
       " \n",
       "         [[ 0.8702, -1.2522,  0.2274, -1.0835]],\n",
       " \n",
       "         [[ 0.9938, -1.2330, -0.4124, -1.0743]],\n",
       " \n",
       "         [[ 0.8595, -0.4764, -0.4192, -0.9798]]]),\n",
       " tensor([[[-0.6127,  1.0152, -1.0313, -2.0852]],\n",
       " \n",
       "         [[-0.4455,  0.8198,  1.0105, -0.5656]],\n",
       " \n",
       "         [[-0.3874,  0.7546, -1.0485, -0.6213]],\n",
       " \n",
       "         [[-0.7256, -2.4891, -1.7670, -1.9850]]]),\n",
       " tensor([[[ 3.1658e-05,  1.1560e+00, -2.1931e+00, -9.7359e-01]],\n",
       " \n",
       "         [[ 9.2789e-01,  5.4331e-01,  8.6473e-01, -2.1324e+00]],\n",
       " \n",
       "         [[ 1.0649e+00,  5.4007e-01, -1.0082e+00, -1.5628e-01]],\n",
       " \n",
       "         [[-6.2773e-01, -1.1013e+00, -2.1031e+00, -1.3680e-01]]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51738a32-484c-4179-9eee-45af0ea722d1",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kernel_data(\n",
    "    alpha1, beta1, alpha2, beta2, num_samples=100, samples_per_kernel=4\n",
    "):\n",
    "    data_list = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        #  Sample Seeds (x1 and x2)\n",
    "        x1 = np.random.normal(loc=alpha1, scale=beta1)\n",
    "        x2 = np.random.normal(loc=alpha2, scale=beta2)\n",
    "\n",
    "        # Process x1 Kernel\n",
    "\n",
    "        # Parameters for the N(mu, sigma) distribution for x1\n",
    "        mu_1 = 2 * x1\n",
    "        sigma_1 = abs(3 * x1)\n",
    "\n",
    "        # Sample 4 values (y) from the distribution\n",
    "        y_samples_1 = np.random.normal(loc=mu_1, scale=sigma_1, size=samples_per_kernel)\n",
    "\n",
    "        # Apply the kernel function\n",
    "        k_values_1 = sigmoid(y_samples_1) + 0.1 * x1\n",
    "\n",
    "        # Process x2 Kernel\n",
    "\n",
    "        # Parameters for the N(mu, sigma) distribution for x2\n",
    "        mu_2 = x2**2\n",
    "        sigma_2 = abs(3 * x2)\n",
    "\n",
    "        # Sample 4 values (y) from the distribution\n",
    "        y_samples_2 = np.random.normal(loc=mu_2, scale=sigma_2, size=samples_per_kernel)\n",
    "\n",
    "        # This replaces any non-positive y with a small positive number (1e-6)\n",
    "        y_samples_2[y_samples_2 <= 0] = 1e-6\n",
    "\n",
    "        # Apply the kernel function: (1 / sqrt(y)) * abs(x2)\n",
    "        k_values_2 = (1 / np.sqrt(y_samples_2)) * abs(x2)\n",
    "\n",
    "        row_data = {\n",
    "            \"x1_seed\": x1,\n",
    "            \"x2_seed\": x2,\n",
    "        }\n",
    "\n",
    "        for j in range(samples_per_kernel):\n",
    "            row_data[f\"k1_output_{j + 1}\"] = k_values_1[j]\n",
    "            row_data[f\"k2_output_{j + 1}\"] = k_values_2[j]\n",
    "\n",
    "        data_list.append(row_data)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d80b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = generate_kernel_data(\n",
    "    alpha1=5, beta1=10, alpha2=15, beta2=20, num_samples=100, samples_per_kernel=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc108e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_seed</th>\n",
       "      <th>x2_seed</th>\n",
       "      <th>k1_output_1</th>\n",
       "      <th>k2_output_1</th>\n",
       "      <th>k1_output_2</th>\n",
       "      <th>k2_output_2</th>\n",
       "      <th>k1_output_3</th>\n",
       "      <th>k2_output_3</th>\n",
       "      <th>k1_output_4</th>\n",
       "      <th>k2_output_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.974569</td>\n",
       "      <td>-8.726524</td>\n",
       "      <td>2.697454</td>\n",
       "      <td>1.042234</td>\n",
       "      <td>2.697457</td>\n",
       "      <td>0.861392</td>\n",
       "      <td>1.697462</td>\n",
       "      <td>1.066583</td>\n",
       "      <td>2.697457</td>\n",
       "      <td>0.818430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.550550</td>\n",
       "      <td>15.657805</td>\n",
       "      <td>0.140813</td>\n",
       "      <td>0.856635</td>\n",
       "      <td>-0.855055</td>\n",
       "      <td>0.959655</td>\n",
       "      <td>-0.855055</td>\n",
       "      <td>0.906347</td>\n",
       "      <td>-0.855055</td>\n",
       "      <td>0.887822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.493067</td>\n",
       "      <td>15.674365</td>\n",
       "      <td>0.760730</td>\n",
       "      <td>0.982754</td>\n",
       "      <td>1.749302</td>\n",
       "      <td>1.141796</td>\n",
       "      <td>0.749920</td>\n",
       "      <td>0.887147</td>\n",
       "      <td>1.749302</td>\n",
       "      <td>0.964876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.156695</td>\n",
       "      <td>17.911992</td>\n",
       "      <td>1.102111</td>\n",
       "      <td>0.847279</td>\n",
       "      <td>1.112339</td>\n",
       "      <td>0.993034</td>\n",
       "      <td>1.091787</td>\n",
       "      <td>0.855107</td>\n",
       "      <td>0.751819</td>\n",
       "      <td>1.015220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.550308</td>\n",
       "      <td>-5.750766</td>\n",
       "      <td>-0.955024</td>\n",
       "      <td>1.023174</td>\n",
       "      <td>0.044969</td>\n",
       "      <td>0.951915</td>\n",
       "      <td>-0.949947</td>\n",
       "      <td>0.882685</td>\n",
       "      <td>-0.948986</td>\n",
       "      <td>0.688759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1_seed    x2_seed  k1_output_1  k2_output_1  k1_output_2  k2_output_2  \\\n",
       "0  16.974569  -8.726524     2.697454     1.042234     2.697457     0.861392   \n",
       "1  -8.550550  15.657805     0.140813     0.856635    -0.855055     0.959655   \n",
       "2   7.493067  15.674365     0.760730     0.982754     1.749302     1.141796   \n",
       "3   1.156695  17.911992     1.102111     0.847279     1.112339     0.993034   \n",
       "4  -9.550308  -5.750766    -0.955024     1.023174     0.044969     0.951915   \n",
       "\n",
       "   k1_output_3  k2_output_3  k1_output_4  k2_output_4  \n",
       "0     1.697462     1.066583     2.697457     0.818430  \n",
       "1    -0.855055     0.906347    -0.855055     0.887822  \n",
       "2     0.749920     0.887147     1.749302     0.964876  \n",
       "3     1.091787     0.855107     0.751819     1.015220  \n",
       "4    -0.949947     0.882685    -0.948986     0.688759  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e53787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use different distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d986dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7df5f4-e786-42ef-bb82-8feb0a352dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
